# Financial Sentiment Analysis Pipeline

A modular, production-ready pipeline for sentiment analysis of financial news articles using FinBERT and enhanced NER.

## ğŸ—ï¸ Project Structure

```
FinancialSentimentAnalysis/
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ settings.py          # Centralized configuration
â”‚
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ sentiment.py         # Unified sentiment analysis
â”‚   â”œâ”€â”€ ner.py              # Enhanced NER system
â”‚   â”œâ”€â”€ aggregator.py       # Sentiment aggregation
â”‚   â””â”€â”€ text_processor.py   # Text preprocessing
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ loader.py           # Data loading and collection
â”‚   â”œâ”€â”€ builder.py          # Ticker list builders
â”‚   â””â”€â”€ validator.py        # Data validation
â”‚
â”œâ”€â”€ pipelines/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_pipeline.py    # Base pipeline class
â”‚   â”œâ”€â”€ main_pipeline.py    # Main implementations
â”‚   â””â”€â”€ baselines.py        # Baseline models (VADER)
â”‚
â”œâ”€â”€ analysis/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ comparison.py       # Results comparison
â”‚   â”œâ”€â”€ visualization.py    # Plotting functions
â”‚   â””â”€â”€ evaluation.py       # Evaluation metrics
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ helpers.py          # General utilities
â”‚   â””â”€â”€ colab_utils.py      # Colab-specific utilities
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ run_pipeline.py     # Main entry point
â”‚   â”œâ”€â”€ run_experiments.py  # Run all experiments
â”‚   â””â”€â”€ setup_data.py       # Data setup
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ main_analysis.ipynb # Colab notebook
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ test_pipeline.py    # Unit tests
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸš€ Quick Start

### 1. Installation

```bash
# Clone repository
git clone https://github.com/yourusername/FinancialSentimentAnalysis.git
cd FinancialSentimentAnalysis

# Install dependencies
pip install -r requirements.txt

# Download NLTK data
python -c "import nltk; nltk.download('punkt')"
```

### 2. Data Collection (Optional)

```bash
# Collect financial news data
python data/loader.py
```

### 3. Run Pipeline

```bash
# Run optimized pipeline (recommended)
python scripts/run_pipeline.py --pipeline optimized

# Run with custom settings
python scripts/run_pipeline.py \
    --pipeline optimized \
    --batch-size 100 \
    --threshold 0.15 \
    --output results/my_results.jsonl
```

### 4. Run All Experiments

```bash
# Run complete comparison
python scripts/run_experiments.py
```

## ğŸ“Š Pipeline Options

### Sentiment Modes

1. **Standard**: Original FinBERT without modifications
2. **Optimized**: With bias correction (recommended)
3. **Calibrated**: Advanced bias reduction

### Aggregation Methods

1. **default**: Simple count-based
2. **majority**: Majority voting
3. **conf_weighted**: Confidence-weighted (recommended)

### Example Commands

```bash
# Standard pipeline (baseline)
python scripts/run_pipeline.py --pipeline standard

# VADER baseline
python scripts/run_pipeline.py --pipeline vader --vader-threshold 0.05

# Optimized with custom threshold
python scripts/run_pipeline.py --pipeline optimized --threshold 0.15

# Calibrated with majority voting
python scripts/run_pipeline.py --pipeline calibrated --method majority
```

## ğŸ”§ Configuration

Edit `config/settings.py` to customize:

- API tokens
- Model parameters
- Processing thresholds
- Batch sizes
- Output directories

## ğŸ“ˆ Key Features

### Enhanced NER

- Context-aware ticker extraction
- Exchange suffix handling (.US, .TO, etc.)
- Company name recognition
- Confidence scoring

### Sentiment Analysis

- Multiple modes (standard/optimized/calibrated)
- Bias reduction techniques
- Batch processing optimization
- GPU support

### Aggregation

- Ticker-level sentiment
- Sector-level rollup
- Article-level summary
- Configurable methods

### Analysis Tools

- Results comparison
- Visualization generation
- Performance metrics
- Statistical reports

## ğŸ¯ Results

The optimized pipeline achieves:

- **Neutral bias reduction**: From ~80% to ~63% (16.6pp improvement)
- **Ticker coverage**: 87.5% of articles
- **Average tickers/article**: 3.01
- **Processing speed**: ~1000 articles/minute on GPU

## ğŸ“ Output Format

Each processed article produces a JSON record:

```json
{
  "date": "2024-01-15",
  "title": "Apple Reports Q4 Earnings...",
  "overall_sentiment": "Positive",
  "overall_confidence": 0.89,
  "tickers": [
    {
      "symbol": "AAPL",
      "label": "Positive",
      "score": 0.75,
      "confidence": 0.92
    }
  ],
  "sectors": [
    {
      "sector": "Technology",
      "label": "Positive",
      "score": 0.68,
      "confidence": 0.88
    }
  ]
}
```

## ğŸ§ª Testing

```bash
# Run tests
python -m pytest tests/

# Test specific component
python -m pytest tests/test_pipeline.py::test_sentiment_analysis
```

## ğŸ“Š Visualization

The analysis module generates:

- Sentiment distribution plots
- Ticker coverage analysis
- Neutral bias reduction charts
- Performance comparisons

## ğŸš€ Google Colab

For Google Colab usage:

```python
# Clone repository
!git clone https://github.com/yourusername/FinancialSentimentAnalysis.git
%cd FinancialSentimentAnalysis

# Install requirements
!pip install -r requirements.txt

# Run pipeline
!python scripts/run_pipeline.py --batch-size 50 --max-articles 1000
```

## ğŸ“„ License

MIT License - see LICENSE file for details

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open Pull Request

## ğŸ“§ Contact

For questions or issues, please open a GitHub issue or contact the maintainers.
